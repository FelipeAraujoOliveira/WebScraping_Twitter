{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless=new\")\n",
    "options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\")\n",
    "driver = webdriver.Chrome(options=options)\n",
    "driver.get(\"https://x.com/login\")\n",
    "time.sleep(5)\n",
    "\n",
    "try:\n",
    "    username = driver.find_element(By.NAME, \"text\")\n",
    "    username.send_keys(os.getenv('USER'))\n",
    "    username.send_keys(Keys.RETURN)\n",
    "    time.sleep(3)\n",
    "    password = driver.find_element(By.NAME, \"password\")\n",
    "    password.send_keys(os.getenv('PASSWORD'))\n",
    "    password.send_keys(Keys.RETURN)\n",
    "    time.sleep(5)\n",
    "    print(\"Login realizado com sucesso\")\n",
    "\n",
    "    query = \"SUA QUERY\"\n",
    "    driver.get(f\"https://x.com/search?q={query}&src=typed_query&f=live\")\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    tweets = []\n",
    "    users = []\n",
    "    seen_tweets = set()\n",
    "    scroll_attempts = 0\n",
    "    max_scroll_attempts = 10\n",
    "\n",
    "    while scroll_attempts < max_scroll_attempts:\n",
    "        elements = wait.until(EC.visibility_of_all_elements_located(\n",
    "            (By.XPATH, \"//*[@data-testid='tweetText'] | //*[@data-testid='User-Name']\")\n",
    "        ))\n",
    "        current_user = None\n",
    "\n",
    "        for el in elements:\n",
    "            if el.get_attribute(\"data-testid\") == \"User-Name\":\n",
    "                text = el.text.strip()\n",
    "                match = re.search(r\"(.+)\\n(@\\w+)\", text)\n",
    "\n",
    "                if match:\n",
    "                    name = match.group(1).strip()\n",
    "                    at = match.group(2).strip()\n",
    "                    current_user = (name, at)\n",
    "\n",
    "            elif el.get_attribute(\"data-testid\") == \"tweetText\":\n",
    "                tweet_text = el.text.strip()\n",
    "\n",
    "                if query.lower() in tweet_text.lower() and current_user and tweet_text not in seen_tweets:\n",
    "                    users.append(current_user)\n",
    "                    tweets.append(tweet_text)\n",
    "                    seen_tweets.add(tweet_text)\n",
    "                    current_user = None\n",
    "\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(1)\n",
    "        scroll_attempts += 1\n",
    "        print(f'{scroll_attempts} / {max_scroll_attempts}')\n",
    "\n",
    "    df = pd.DataFrame(users, columns=['Name', 'At'])\n",
    "    df['Tweet'] = tweets \n",
    "    df.to_csv('../data/tweets.csv', index=False)\n",
    "    print(df.head())\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Erro ao buscar tweets:\", e)\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "stopwords_pt = set(stopwords.words('portuguese'))\n",
    "\n",
    "internet_stopwords = [\n",
    "    \"q\", \"pq\", \"p\", \"pra\", \"pro\", \"ta\", \"tá\", \"né\", \"blz\", \"vlw\", \"obg\", \"obrigado\",  \n",
    "    \"obrigada\", \"td\", \"tudo\", \"c\", \"vc\", \"vcs\", \"tb\", \"tbm\", \"tbem\", \"aki\", \"aqui\",  \n",
    "    \"kd\", \"cadê\", \"d\", \"de\", \"hj\", \"hoje\", \"amanha\", \"dps\", \"depois\", \"s\", \"sim\", \"n\", \"nao\",  \n",
    "    \"não\", \"mt\", \"muito\", \"mta\", \"muita\", \"mto\", \"muitos\", \"muitas\", \"eh\", \"é\", \"da\", \"das\",  \n",
    "    \"do\", \"dos\", \"aq\", \"aí\", \"aí\", \"blz\", \"beleza\", \"flw\", \"falou\", \"tipo\", \"msm\", \"mesmo\",  \n",
    "    \"mesma\", \"qm\", \"quem\", \"qlq\", \"qualquer\", \"aff\", \"pff\", \"pfv\", \"porfavor\", \"favor\",  \n",
    "    \"cmg\", \"comigo\", \"ctg\", \"contigo\", \"ngm\", \"ninguém\", \"qnd\", \"quando\", \"tb\", \"também\",  \n",
    "    \"bora\", \"partiu\", \"sei\", \"sabe\", \"sabe\", \"sabe\", \"sqn\", \"so\", \"só\", \"vamo\", \"vamos\",  \n",
    "    \"bjs\", \"beijos\", \"bj\", \"beijo\", \"bjo\", \"blza\", \"beleza\", \"eh\", \"é\", \"ow\", \"ou\",  \n",
    "    \"axei\", \"achei\", \"pq\", \"porque\", \"qdo\", \"quando\", \"nem\", \"po\", \"pô\", \"mano\", \"véi\",\n",
    "    \"véio\", \"nn\", \"vdd\", \"vo\", \"ia\", \"mds\", \"vi\", \"vem\", \"qq\", \"ai\", \"cada\", \"ver\", \"onde\", \n",
    "    \"amg\", \"tô\", \"bom\", \"dá\", \"ja\", \"fiz\", \"uns\", \"um\", \"lá\", \"ir\", \"vai\", \"ter\", \"fazer\", \"gente\",\n",
    "    \"oq\", \"bem\", \"agr\", \"faço\", \"logo\", \"tao\", \"tão\", \"vejo\", \"nessa\", \"nesta\", \"indo\", \"tanto\", \"fica\",\n",
    "    \"voce\"\n",
    "]\n",
    "\n",
    "df = pd.read_csv('../data/tweets.csv')\n",
    "\n",
    "def clean_tweet(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'http\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = ' '.join([word for word in text.split() if word not in stopwords_pt and word not in internet_stopwords])\n",
    "    return text\n",
    "\n",
    "df['Clean_Tweet'] = df['Tweet'].apply(clean_tweet)\n",
    "text = ' '.join(df['Clean_Tweet'])\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
